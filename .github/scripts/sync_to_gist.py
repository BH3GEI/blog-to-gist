# .github/scripts/sync_to_gist.py
import github
from github import Github, GithubException
import os
import json
import logging
import requests
from urllib.parse import quote
from tenacity import retry, stop_after_attempt, wait_exponential
from typing import List, Dict

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# å¸¸é‡é…ç½®
BLOG_REPO = "BH3GEI/blog"
BRANCH = "main"
LIST_JSON_PATH = "list.json"  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
MAX_RETRIES = 3

@retry(
    stop=stop_after_attempt(MAX_RETRIES),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    before_sleep=lambda _: logger.warning("è¯·æ±‚å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
)
def fetch_remote_content(url: str, token: str = None) -> str:
    """å®‰å…¨è·å–è¿œç¨‹å†…å®¹ï¼ˆè‡ªåŠ¨é‡è¯•ï¼‰"""
    headers = {"User-Agent": "BlogSync/1.0"}
    if token:
        headers["Authorization"] = f"token {token}"
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        if len(response.content) == 0:
            raise ValueError("å“åº”å†…å®¹ä¸ºç©º")
        return response.text
    except requests.exceptions.RequestException as e:
        logger.error(f"è¯·æ±‚å¤±è´¥: {e.response.status_code if e.response else 'æ— å“åº”'} - {url}")
        raise

def generate_raw_url(file_path: str) -> str:
    """ç”ŸæˆGitHub Raw URLï¼ˆè‡ªåŠ¨ç¼–ç è·¯å¾„ï¼‰"""
    encoded_path = quote(file_path.strip('/'), safe='/')
    return f"https://raw.githubusercontent.com/{BLOG_REPO}/{BRANCH}/{encoded_path}"


def load_blog_list(token: str) -> List[Dict]:
    """åŠ è½½è¿œç¨‹åšå®¢åˆ—è¡¨"""
    list_url = generate_raw_url(LIST_JSON_PATH)
    logger.info(f"æ­£åœ¨è·å–åšå®¢åˆ—è¡¨: {list_url}")
    
    try:
        content = fetch_remote_content(list_url, token)
        data = json.loads(content)
        
        # æ ¡éªŒæ•°æ®ç»“æ„
        if not isinstance(data, list):
            raise ValueError("list.json åº”è¯¥æ˜¯ä¸€ä¸ªæ•°ç»„")
        required_fields = ['title', 'file', 'time']
        for idx, item in enumerate(data):
            if not all(field in item for field in required_fields):
                raise ValueError(f"ç¬¬ {idx+1} é¡¹ç¼ºå°‘å¿…è¦å­—æ®µ")
        return data
    except json.JSONDecodeError:
        logger.error("JSONè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥list.jsonæ ¼å¼")
        raise

def format_gist_content(title: str, date: str, content: str) -> str:
    """ç”Ÿæˆå¸¦å…ƒæ•°æ®çš„Gistå†…å®¹"""
    return f"""# {title}

> Published on {date}

---

{content}
"""

def sync_to_gist():
    try:
        # è·å–ç¯å¢ƒå˜é‡
        gh_token = os.environ.get('GH_TOKEN')
        if not gh_token:
            raise EnvironmentError("ç¼ºå°‘ GH_TOKEN ç¯å¢ƒå˜é‡")

        # åˆå§‹åŒ–GitHubå®¢æˆ·ç«¯
        gh = Github(gh_token, timeout=30)
        user = gh.get_user()
        logger.info(f"å·²è®¤è¯ä¸º: {user.login}")

        # è·å–åšå®¢åˆ—è¡¨
        posts = load_blog_list(gh_token)
        logger.info(f"æˆåŠŸåŠ è½½ {len(posts)} ç¯‡æ–‡ç« ")

        # è·å–ç°æœ‰Gist
        existing_gists = {gist.description: gist for gist in user.get_gists() if gist.description}

        # å¤„ç†æ¯ç¯‡æ–‡ç« 
        success_count = 0
        for idx, post in enumerate(posts, 1):
            try:
                # æ ¡éªŒæ•°æ®
                title = post['title']
                date = post['time']
                file_path = post['file']
                description = f"ğŸ“ {title} | {date}"
                
                if not all([title, date, file_path]):
                    raise ValueError("æ–‡ç« æ•°æ®ä¸å®Œæ•´")

                # è·å–æ–‡ç« å†…å®¹
                file_url = generate_raw_url(file_path)
                logger.debug(f"æ­£åœ¨è·å–: {file_url}")
                content = fetch_remote_content(file_url, gh_token)
                
                # æ„å»ºGistå†…å®¹
                full_content = format_gist_content(title, date, content)
                filename = os.path.basename(file_path)

                # åŒæ­¥é€»è¾‘
                if description in existing_gists:
                    gist = existing_gists[description]
                    current_content = next(iter(gist.files.values())).content
                    
                    if current_content == full_content:
                        logger.info(f"#{idx} [SKIP] æ— å˜åŒ–: {title}")
                        continue
                    
                    gist.edit(
                        description=description,
                        files={filename: {'content': full_content}}
                    )
                    logger.info(f"#{idx} [UPDATE] æ›´æ–°æˆåŠŸ: {title}")
                else:
                    user.create_gist(
                        public=True,
                        description=description,
                        files={filename: {'content': full_content}}
                    )
                    logger.info(f"#{idx} [CREATE] åˆ›å»ºæˆåŠŸ: {title}")
                
                success_count += 1

            except Exception as e:
                logger.error(f"#{idx} å¤„ç†å¤±è´¥: {title} - {str(e)}")
                continue

        logger.info(f"åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count}/{len(posts)} ç¯‡æ–‡ç« ")

    except Exception as e:
        logger.critical(f"è‡´å‘½é”™è¯¯: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    sync_to_gist()
